{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *MNIST数据集的读取*\r\n",
    "*传出的数据为图像的标签 train_label和图像的像素值 train_image*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "魔数:2051, 图片数量: 60000张, 图片大小: 28*28\n",
      "16\n",
      ">784B 16 784\n",
      "已解析 10000张\n",
      "7839232\n",
      "已解析 20000张\n",
      "15679232\n",
      "已解析 30000张\n",
      "23519232\n",
      "已解析 40000张\n",
      "31359232\n",
      "已解析 50000张\n",
      "39199232\n",
      "已解析 60000张\n",
      "47039232\n",
      "魔数:2049, 图片数量: 60000张\n",
      "已解析 10000张\n",
      "已解析 20000张\n",
      "已解析 30000张\n",
      "已解析 40000张\n",
      "已解析 50000张\n",
      "已解析 60000张\n",
      "5.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "import struct\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import cv2\r\n",
    "import random\r\n",
    "import time\r\n",
    "\r\n",
    "# 训练集文件\r\n",
    "train_images_idx3_ubyte_file = 'dataset/mnist_dataset/train-images.idx3-ubyte'\r\n",
    "# 训练集标签文件\r\n",
    "train_labels_idx1_ubyte_file = 'dataset/mnist_dataset/train-labels.idx1-ubyte'\r\n",
    "\r\n",
    "# 测试集文件\r\n",
    "test_images_idx3_ubyte_file = 'dataset/mnist_dataset/t10k-images.idx3-ubyte'\r\n",
    "# 测试集标签文件\r\n",
    "test_labels_idx1_ubyte_file = 'dataset/mnist_dataset/t10k-labels.idx1-ubyte'\r\n",
    "\r\n",
    "\r\n",
    "def decode_idx3_ubyte(idx3_ubyte_file):\r\n",
    "    \"\"\"\r\n",
    "    解析idx3文件的通用函数\r\n",
    "    :param idx3_ubyte_file: idx3文件路径\r\n",
    "    :return: 数据集\r\n",
    "    \"\"\"\r\n",
    "    # 读取二进制数据\r\n",
    "    bin_data = open(idx3_ubyte_file, 'rb').read()\r\n",
    "\r\n",
    "    # 解析文件头信息，依次为魔数、图片数量、每张图片高、每张图片宽\r\n",
    "    offset = 0\r\n",
    "    fmt_header = '>iiii' #因为数据结构中前4行的数据类型都是32位整型，所以采用i格式，但我们需要读取前4行数据，所以需要4个i。我们后面会看到标签集中，只使用2个ii。\r\n",
    "    magic_number, num_images, num_rows, num_cols = struct.unpack_from(fmt_header, bin_data, offset)\r\n",
    "    print('魔数:%d, 图片数量: %d张, 图片大小: %d*%d' % (magic_number, num_images, num_rows, num_cols))\r\n",
    "\r\n",
    "    # 解析数据集\r\n",
    "    image_size = num_rows * num_cols\r\n",
    "    offset += struct.calcsize(fmt_header)  #获得数据在缓存中的指针位置，从前面介绍的数据结构可以看出，读取了前4行之后，指针位置（即偏移位置offset）指向0016。\r\n",
    "    print(offset)\r\n",
    "    fmt_image = '>' + str(image_size) + 'B'  #图像数据像素值的类型为unsigned char型，对应的format格式为B。这里还有加上图像大小784，是为了读取784个B格式数据，如果没有则只会读取一个值（即一副图像中的一个像素值）\r\n",
    "    print(fmt_image,offset,struct.calcsize(fmt_image))\r\n",
    "    images = np.empty((num_images, num_rows, num_cols))\r\n",
    "    #plt.figure()\r\n",
    "    for i in range(num_images):\r\n",
    "        if (i + 1) % 10000 == 0:\r\n",
    "            print('已解析 %d' % (i + 1) + '张')\r\n",
    "            print(offset)\r\n",
    "        images[i] = np.array(struct.unpack_from(fmt_image, bin_data, offset)).reshape((num_rows, num_cols))\r\n",
    "        #print(images[i])\r\n",
    "        offset += struct.calcsize(fmt_image)\r\n",
    "#        plt.imshow(images[i],'gray')\r\n",
    "#        plt.pause(0.00001)\r\n",
    "#        plt.show()\r\n",
    "    #plt.show()\r\n",
    "\r\n",
    "    return images\r\n",
    "\r\n",
    "\r\n",
    "def decode_idx1_ubyte(idx1_ubyte_file):\r\n",
    "    \"\"\"\r\n",
    "    解析idx1文件的通用函数\r\n",
    "    :param idx1_ubyte_file: idx1文件路径\r\n",
    "    :return: 数据集\r\n",
    "    \"\"\"\r\n",
    "    # 读取二进制数据\r\n",
    "    bin_data = open(idx1_ubyte_file, 'rb').read()\r\n",
    "\r\n",
    "    # 解析文件头信息，依次为魔数和标签数\r\n",
    "    offset = 0\r\n",
    "    fmt_header = '>ii'\r\n",
    "    magic_number, num_images = struct.unpack_from(fmt_header, bin_data, offset)\r\n",
    "    print('魔数:%d, 图片数量: %d张' % (magic_number, num_images))\r\n",
    "\r\n",
    "    # 解析数据集\r\n",
    "    offset += struct.calcsize(fmt_header)\r\n",
    "    fmt_image = '>B'\r\n",
    "    labels = np.empty(num_images)\r\n",
    "    for i in range(num_images):\r\n",
    "        if (i + 1) % 10000 == 0:\r\n",
    "            print ('已解析 %d' % (i + 1) + '张')\r\n",
    "        labels[i] = struct.unpack_from(fmt_image, bin_data, offset)[0]\r\n",
    "        offset += struct.calcsize(fmt_image)\r\n",
    "    return labels\r\n",
    "\r\n",
    "\r\n",
    "def load_train_images(idx_ubyte_file=train_images_idx3_ubyte_file):\r\n",
    "    \"\"\"\r\n",
    "    TRAINING SET IMAGE FILE (train-images-idx3-ubyte):\r\n",
    "    [offset] [type]          [value]          [description]\r\n",
    "    0000     32 bit integer  0x00000803(2051) magic number\r\n",
    "    0004     32 bit integer  60000            number of images\r\n",
    "    0008     32 bit integer  28               number of rows\r\n",
    "    0012     32 bit integer  28               number of columns\r\n",
    "    0016     unsigned byte   ??               pixel\r\n",
    "    0017     unsigned byte   ??               pixel\r\n",
    "    ........\r\n",
    "    xxxx     unsigned byte   ??               pixel\r\n",
    "    Pixels are organized row-wise. Pixel values are 0 to 255. 0 means background (white), 255 means foreground (black).\r\n",
    "\r\n",
    "    :param idx_ubyte_file: idx文件路径\r\n",
    "    :return: n*row*col维np.array对象，n为图片数量\r\n",
    "    \"\"\"\r\n",
    "    return decode_idx3_ubyte(idx_ubyte_file)\r\n",
    "\r\n",
    "\r\n",
    "def load_train_labels(idx_ubyte_file=train_labels_idx1_ubyte_file):\r\n",
    "    \"\"\"\r\n",
    "    TRAINING SET LABEL FILE (train-labels-idx1-ubyte):\r\n",
    "    [offset] [type]          [value]          [description]\r\n",
    "    0000     32 bit integer  0x00000801(2049) magic number (MSB first)\r\n",
    "    0004     32 bit integer  60000            number of items\r\n",
    "    0008     unsigned byte   ??               label\r\n",
    "    0009     unsigned byte   ??               label\r\n",
    "    ........\r\n",
    "    xxxx     unsigned byte   ??               label\r\n",
    "    The labels values are 0 to 9.\r\n",
    "\r\n",
    "    :param idx_ubyte_file: idx文件路径\r\n",
    "    :return: n*1维np.array对象，n为图片数量\r\n",
    "    \"\"\"\r\n",
    "    return decode_idx1_ubyte(idx_ubyte_file)\r\n",
    "\r\n",
    "\r\n",
    "def load_test_images(idx_ubyte_file=test_images_idx3_ubyte_file):\r\n",
    "    \"\"\"\r\n",
    "    TEST SET IMAGE FILE (t10k-images-idx3-ubyte):\r\n",
    "    [offset] [type]          [value]          [description]\r\n",
    "    0000     32 bit integer  0x00000803(2051) magic number\r\n",
    "    0004     32 bit integer  10000            number of images\r\n",
    "    0008     32 bit integer  28               number of rows\r\n",
    "    0012     32 bit integer  28               number of columns\r\n",
    "    0016     unsigned byte   ??               pixel\r\n",
    "    0017     unsigned byte   ??               pixel\r\n",
    "    ........\r\n",
    "    xxxx     unsigned byte   ??               pixel\r\n",
    "    Pixels are organized row-wise. Pixel values are 0 to 255. 0 means background (white), 255 means foreground (black).\r\n",
    "\r\n",
    "    :param idx_ubyte_file: idx文件路径\r\n",
    "    :return: n*row*col维np.array对象，n为图片数量\r\n",
    "    \"\"\"\r\n",
    "    return decode_idx3_ubyte(idx_ubyte_file)\r\n",
    "\r\n",
    "\r\n",
    "def load_test_labels(idx_ubyte_file=test_labels_idx1_ubyte_file):\r\n",
    "    \"\"\"\r\n",
    "    TEST SET LABEL FILE (t10k-labels-idx1-ubyte):\r\n",
    "    [offset] [type]          [value]          [description]\r\n",
    "    0000     32 bit integer  0x00000801(2049) magic number (MSB first)\r\n",
    "    0004     32 bit integer  10000            number of items\r\n",
    "    0008     unsigned byte   ??               label\r\n",
    "    0009     unsigned byte   ??               label\r\n",
    "    ........\r\n",
    "    xxxx     unsigned byte   ??               label\r\n",
    "    The labels values are 0 to 9.\r\n",
    "\r\n",
    "    :param idx_ubyte_file: idx文件路径\r\n",
    "    :return: n*1维np.array对象，n为图片数量\r\n",
    "    \"\"\"\r\n",
    "    return decode_idx1_ubyte(idx_ubyte_file)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "if __name__ == '__main__':\r\n",
    "    # train_labels存储标签信息（一位小数）\r\n",
    "    # train_images则存储图片的像素信息（每张图像以28*28数组存储，元素数量为图像总数量）\r\n",
    "    train_image = load_train_images()\r\n",
    "\r\n",
    "    train_label = load_train_labels()\r\n",
    "    # test_images = load_test_images()\r\n",
    "    # test_labels = load_test_labels()\r\n",
    "\r\n",
    "    # 查看前十个数据及其标签以读取是否正确\r\n",
    "    for i in range(10):\r\n",
    "        print(train_label[i])\r\n",
    "        plt.imshow(train_image[i], cmap='gray')\r\n",
    "        plt.pause(0.000001)\r\n",
    "        plt.show()\r\n",
    "    print('done')\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *验证数据的读取结果*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "8.0\n",
      "(60000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_image))\r\n",
    "\r\n",
    "# 打印最后一张图像的像素值信息\r\n",
    "# print(list(train_images[len(train_images) - 1]))\r\n",
    "\r\n",
    "#打印第一张图像的标签\r\n",
    "print(train_label[len(train_label) - 1])\r\n",
    "\r\n",
    "print(np.shape(train_image))\r\n",
    "\r\n",
    "a = []\r\n",
    "a.append(0)\r\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *清洗数据集便于实现二分类*\r\n",
    "* 其中5为1，8为-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11272\n",
      "11272\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "#搜索可进行优化\r\n",
    "\r\n",
    "train_images = []\r\n",
    "labels = []\r\n",
    "for i in range(len(train_label)):\r\n",
    "    if (train_label[i] == 5):\r\n",
    "        #train_images = np.delete(train_images,i,axis=0)\r\n",
    "        labels.append(1)\r\n",
    "        train_images.append(train_image[i])\r\n",
    "    if (train_label[i] == 8):\r\n",
    "        labels.append(-1)\r\n",
    "        train_images.append(train_image[i])\r\n",
    "\r\n",
    "print(len(labels))\r\n",
    "print(len(train_images))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *图像特征空间的选择*\r\n",
    "* 整个图像作为特征向量：图像像素数值为特征空间 规模：28 * 28\r\n",
    "* HOG特征\r\n",
    "* 提取灰度（利用黑白特征）直方图的相关信息作为特征空间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\r\n",
    "warnings.filterwarnings(\"ignore\")\r\n",
    "# 整个图像像素作为特征向量，即直接使用train_images数组即可\r\n",
    "\r\n",
    "def get_full_features(train_images):\r\n",
    "    features = []\r\n",
    "    \r\n",
    "    for img in train_images:\r\n",
    "        img = np.reshape(img,(28,28))\r\n",
    "        img = img.astype(np.uint8)\r\n",
    "\r\n",
    "        features.append(img)\r\n",
    "\r\n",
    "    features = np.array(features)\r\n",
    "    features = np.reshape(features,(-1,28 * 28))\r\n",
    "\r\n",
    "    return features\r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#利用库函数提取hog特征\r\n",
    "def get_hog_features(train_images):\r\n",
    "    features = []\r\n",
    " \r\n",
    "#hog函数的参数封装于hog.xml配置文件\r\n",
    "    hog = cv2.HOGDescriptor('./hog.xml')\r\n",
    " \r\n",
    "    for img in train_images:\r\n",
    "        img = np.reshape(img,(28,28))\r\n",
    "        cv_img = img.astype(np.uint8)\r\n",
    " \r\n",
    "        hog_feature = hog.compute(cv_img)\r\n",
    "        # hog_feature = np.transpose(hog_feature)\r\n",
    "        features.append(hog_feature)\r\n",
    " \r\n",
    "    features = np.array(features)\r\n",
    "    features = np.reshape(features,(-1,324))\r\n",
    " \r\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *基于感知器准则的线性分类器*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sense(features, train_labels, size):\r\n",
    "\r\n",
    "    feature_size = size * size \r\n",
    "    study_step = 1e-3\r\n",
    "\r\n",
    "    train_size = len(train_labels)\r\n",
    "\r\n",
    "    # 初始化参数矩阵，此处方便计算选择将截距b放于矩阵外\r\n",
    "    w = np.ones((feature_size,1))\r\n",
    "    b = 10\r\n",
    "    \r\n",
    "    correct_count = 1\r\n",
    "    count_max = 1e6\r\n",
    "    count = 1\r\n",
    "    result = 0\r\n",
    "\r\n",
    "#感知器算法设计两层迭代，实现w更新后对判别result的计算更新\r\n",
    "    while True:\r\n",
    "        index = 0\r\n",
    "        for index in range(train_size):\r\n",
    "\r\n",
    "            x = features[index]\r\n",
    "            label = train_labels[index]\r\n",
    "\r\n",
    "        #判别函数，若判断错误则置为负（二分类判断是否准确）\r\n",
    "            result = (np.dot(x.T,w) + b) * label\r\n",
    "\r\n",
    "            count += 1\r\n",
    "        #若当前判别错误，即函数值 < 0，则判断错误，需要更新w和b\r\n",
    "            if (result < 0):\r\n",
    "                #判定\r\n",
    "                x = x.reshape((feature_size,1))\r\n",
    "                #result = abs(np.dot(x.T,w) + b)\r\n",
    "                #x = np.reshape(features[index], (feature_size, 1))\r\n",
    "                #更新参数\r\n",
    "                w += x * study_step * label  \r\n",
    "                b += study_step * label\r\n",
    "                #由于b对应的增广矩阵元素为1\r\n",
    "                correct_count = 0\r\n",
    "                break\r\n",
    "            \r\n",
    "            correct_count += 1\r\n",
    "\r\n",
    "            if count > count_max:\r\n",
    "                return w,b\r\n",
    "\r\n",
    "        if correct_count >= train_size:\r\n",
    "            break\r\n",
    "\r\n",
    "    #print('最小误差为%lf' %result)\r\n",
    "    return w,b "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *基于LMS准则的线性分类器*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先处理训练样本\r\n",
    "def data_matrix(train_features,train_labels):\r\n",
    "    matrix = []\r\n",
    "    for i in range(len(train_labels)):\r\n",
    "        temp = list(train_features[i])\r\n",
    "        temp.append(1)\r\n",
    "        temp = np.array(temp)\r\n",
    "        if(train_labels[i] == 1):\r\n",
    "            matrix.append(np.array(temp))\r\n",
    "        if(train_labels[i] == -1):\r\n",
    "            temp = [-item for item in temp]\r\n",
    "            matrix.append(np.array(temp))\r\n",
    "    matrix = np.array(matrix)\r\n",
    "    return matrix\r\n",
    "\r\n",
    "def classify_LMS(train_features,train_labels,size):\r\n",
    "    feature_size  = size * size\r\n",
    "    study_step = 1e-4\r\n",
    "    study_total = 1e3\r\n",
    "\r\n",
    "    b = np.ones((len(train_labels),1))\r\n",
    "    w = np.zeros((feature_size,1))\r\n",
    "\r\n",
    "    matrix = data_matrix(train_features,train_labels)\r\n",
    "    # 求伪逆\r\n",
    "    matrix_t = np.linalg.pinv(matrix)\r\n",
    "\r\n",
    "    count = 0\r\n",
    "    while(count < study_total):\r\n",
    "        w = np.dot(matrix_t,b)\r\n",
    "        err = np.dot(matrix,w) - b \r\n",
    "        if (err.any() < 0):\r\n",
    "            print(\"ERROR!\")\r\n",
    "            return 0\r\n",
    "\r\n",
    "        if (err.any() == 0):\r\n",
    "            print(\"训练完成!\")\r\n",
    "            return w\r\n",
    "            \r\n",
    "        b += study_step * (err + abs(err))\r\n",
    "        count += 1\r\n",
    "        if count % 1000 == 0:\r\n",
    "            print(count / 1000)\r\n",
    "    print(\"训练未达到最优结果退出!\")\r\n",
    "\r\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *基于Fisher准则的线性分类器*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据拆分为类\r\n",
    "def devide_matrix(train_features,train_labels):\r\n",
    "    #对类中样本数量进行统计\r\n",
    "    count_1 = 0\r\n",
    "    count_2 = 0\r\n",
    "    \r\n",
    "    matrix_1 = []\r\n",
    "    matrix_2 = []\r\n",
    "    for i in range(len(train_labels)):\r\n",
    "        if (train_labels[i] == 1):\r\n",
    "            matrix_1.append(train_features[i])\r\n",
    "            count_1 += 1\r\n",
    "        else:\r\n",
    "            matrix_2.append(train_features[i])\r\n",
    "            count_2 += 1\r\n",
    "\r\n",
    "    return matrix_1,matrix_2,count_1,count_2\r\n",
    "\r\n",
    "# 求矩阵的均值向量\r\n",
    "def get_average(matrix,count):\r\n",
    "    matrix_t = np.transpose(matrix)\r\n",
    "    temp = np.ones((count,1))\r\n",
    "    temp = np.dot(temp,1/count)\r\n",
    "    ans = np.dot(matrix_t,temp)\r\n",
    "    return ans\r\n",
    "\r\n",
    "def get_divergence(vector,matrix,count,size):\r\n",
    "    feature_size = size * size\r\n",
    "    ans = np.zeros((feature_size,feature_size))\r\n",
    "    for i in range(count):\r\n",
    "        temp = np.array(matrix[i] - vector)\r\n",
    "        ans_k = np.dot(temp,temp.T)\r\n",
    "       #print(ans_k.shape)\r\n",
    "        ans += ans_k\r\n",
    "\r\n",
    "    return ans\r\n",
    "\r\n",
    "def classify_Fisher(train_features,train_labels,size):\r\n",
    "    feature_size = size * size\r\n",
    "    matrix_1,matrix_2,count_1,count_2 = devide_matrix(train_features,train_labels)\r\n",
    "    # 求类内聚类指标\r\n",
    "    # 1.求均值向量\r\n",
    "    vector_1 = get_average(matrix_1,count_1)\r\n",
    "    vector_2 = get_average(matrix_2,count_2)\r\n",
    "\r\n",
    "    # 2.计算类内散度矩阵\r\n",
    "    divergence_1 = get_divergence(vector_1,matrix_1,count_1,size)\r\n",
    "    divergence_2 = get_divergence(vector_2,matrix_2,count_2,size)\r\n",
    "\r\n",
    "    # 3.计算总类内散度矩阵\r\n",
    "    divergence = []\r\n",
    "    divergence = np.array(divergence)\r\n",
    "    divergence = divergence_1 + divergence_2\r\n",
    "\r\n",
    "    # 计算最优投影方向和决策分界面\r\n",
    "    w = []\r\n",
    "    w = np.dot(np.linalg.pinv(divergence),(vector_1 - vector_2))\r\n",
    "    # 将两类样本的中间值作为分界点\r\n",
    "    w_a = 0.5 * (vector_1 + vector_2)\r\n",
    "\r\n",
    "    return w,w_a\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *预测结果*\r\n",
    "* 正确则为object_num，错误则为-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict_Sence(testset, w, b):\r\n",
    "    predict = []\r\n",
    "    for i in range(len(testset)):\r\n",
    "        img = testset[i]\r\n",
    "        #img = np.array(img).reshape(-1,1)\r\n",
    "        result = np.dot(w,img) + b\r\n",
    "        if result < 0:\r\n",
    "            result = -1\r\n",
    "        else:\r\n",
    "            result = 1\r\n",
    "        predict.append(result)\r\n",
    "    \r\n",
    "    return np.array(predict).reshape(-1,1)\r\n",
    "\r\n",
    "def Predict_LMS(testset, w):\r\n",
    "    predict = []\r\n",
    "    for i in range(len(testset)):\r\n",
    "        img = testset[i]\r\n",
    "        temp = list(img)\r\n",
    "        temp.append(1)\r\n",
    "        img = np.array(temp)\r\n",
    "        img = img.reshape(-1,1)\r\n",
    "        result = np.dot(w.T,img)\r\n",
    "        if result < 0:\r\n",
    "            result = -1\r\n",
    "        else:\r\n",
    "            result = 1\r\n",
    "        predict.append(result)\r\n",
    "\r\n",
    "    return np.array(predict).reshape(-1,1)\r\n",
    "\r\n",
    "def Predict_Fisher(testset, w ,w_a):\r\n",
    "    predict = []\r\n",
    "    # 投影至一维的决策面\r\n",
    "    res = np.dot(w_a.T,w)\r\n",
    "    for i in range (len(testset)):\r\n",
    "        img = testset[i]\r\n",
    "        temp = np.dot(img,w)\r\n",
    "        if (temp > res):\r\n",
    "            predict.append(1)\r\n",
    "        else:\r\n",
    "            predict.append(-1)\r\n",
    "    return np.array(predict).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *主程序*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "训练未达到最优结果退出!\n",
      "感知器内核二分类器的预测准确率为0.933481\n",
      "LMS内核二分类器的预测准确率为0.996009\n",
      "Fisher内核二分类器的预测准确率为0.949889\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings(\"ignore\")\r\n",
    "\r\n",
    "size = 0\r\n",
    "full_size = 28\r\n",
    "hog_size = 18\r\n",
    "\r\n",
    "p = int(input(\"请输入模式：1为hog，2为全像素\"))\r\n",
    "if p == 1:\r\n",
    "    size = hog_size\r\n",
    "    feature = get_hog_features(train_images)\r\n",
    "elif p == 2:\r\n",
    "    size = full_size\r\n",
    "    feature = get_full_features(train_images)\r\n",
    "else:\r\n",
    "    print(\"invalid input\")\r\n",
    "\r\n",
    "\r\n",
    "#分割数据集\r\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(feature,labels, test_size=0.2)\r\n",
    "#print(len(train_features))\r\n",
    "#print(len(train_labels))\r\n",
    "\r\n",
    "#feature = get_full_features(train_images)\r\n",
    "#print(feature[1])\r\n",
    "\r\n",
    "# 感知器算法\r\n",
    "total = 0\r\n",
    "w_1,b = classify_sense(train_features,train_labels,size)\r\n",
    "w_1 = w_1.reshape(-1,(size * size)).astype(np.int)\r\n",
    "#print(b)\r\n",
    "#print(w)\r\n",
    "\r\n",
    "# LMS算法\r\n",
    "w_2 = classify_LMS(train_features,train_labels,size)\r\n",
    "#print(np.transpose(w))\r\n",
    "\r\n",
    "# Fisher算法\r\n",
    "w_3, w_a = classify_Fisher(train_features,train_labels,size)\r\n",
    "\r\n",
    "test_predict_1 = Predict_Sence(test_features,w_1,b)\r\n",
    "score = accuracy_score(test_labels,test_predict_1)\r\n",
    "print(\"感知器内核二分类器的预测准确率为%lf\" %score)\r\n",
    "\r\n",
    "test_predict_2 = Predict_LMS(test_features,w_2)\r\n",
    "score = accuracy_score(test_labels,test_predict_2)\r\n",
    "print(\"LMS内核二分类器的预测准确率为%lf\" %score) \r\n",
    "\r\n",
    "test_predict_3 = Predict_Fisher(test_features,w_3,w_a)\r\n",
    "score = accuracy_score(test_labels,test_predict_3)\r\n",
    "print(\"Fisher内核二分类器的预测准确率为%lf\" %score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \r\n",
    "from torch.utils.data import DataLoader\r\n",
    "import torchvision.datasets as dsets \r\n",
    "import torchvision.transforms as transforms\r\n",
    "\r\n",
    "batch_size = 100\r\n",
    "# MNIST dataset\r\n",
    "train_dataset = dsets.MNIST(root='./pymnist', train=True, transform=transforms.ToTensor(), download=True)\r\n",
    "test_dataset = dsets.MNIST(root='./pymnist', train=False, transform=transforms.ToTensor(), download=True)\r\n",
    "# load_data\r\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\r\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data: torch.Size([60000, 28, 28])\n",
      "train_labels: torch.Size([60000])\n",
      "test_data: torch.Size([10000, 28, 28])\n",
      "test_labels: torch.Size([10000])\n",
      "batch_size: 100\n",
      "load_train_data: torch.Size([60000, 28, 28])\n",
      "load_train_labels: torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "import warnings\r\n",
    "warnings.filterwarnings(\"ignore\")\r\n",
    "# original_data\r\n",
    "print(\"train_data:\", train_dataset.train_data.size())\r\n",
    "print(\"train_labels:\", train_dataset.train_labels.size())\r\n",
    "print(\"test_data:\", test_dataset.test_data.size())\r\n",
    "print(\"test_labels:\", test_dataset.test_labels.size())\r\n",
    "# shuffle batch_size data\r\n",
    "print(\"batch_size:\", train_loader.batch_size)\r\n",
    "print(\"load_train_data:\", train_loader.dataset.train_data.shape)\r\n",
    "print(\"load_train_labels:\", train_loader.dataset.train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural_net(\n",
      "  (layers1): Linear(in_features=784, out_features=500, bias=True)\n",
      "  (layers2): Linear(in_features=500, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\r\n",
    "\r\n",
    "input_size = 784\r\n",
    "hidden_size = 500\r\n",
    "num_classes = 10\r\n",
    "\r\n",
    "# #定义神经网络模型\r\n",
    "class Neural_net(nn.Module):\r\n",
    "    def __init__(self, input_num, hidden_size, output_num):\r\n",
    "        super(Neural_net, self).__init__()\r\n",
    "        self.layers1 = nn.Linear(input_num, hidden_size)\r\n",
    "        self.layers2 = nn.Linear(hidden_size, output_num)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        out = self.layers1(x)\r\n",
    "        out = torch.relu(out)\r\n",
    "        out = self.layers2(out)\r\n",
    "        return out\r\n",
    "net = Neural_net(input_size, hidden_size, num_classes)\r\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\r\n",
    "\r\n",
    "# training\r\n",
    "learning_rate = 1e-1\r\n",
    "num_epoches = 5\r\n",
    "criterion = nn.CrossEntropyLoss()\r\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\r\n",
    "for epoch in range(num_epoches):\r\n",
    "    #print(\"current epoch = {}\".format(epoch))\r\n",
    "    for i, (images,labels) in enumerate(train_loader):\r\n",
    "        images = Variable(images.view(-1, 28*28))\r\n",
    "        labels = Variable(labels)\r\n",
    "\r\n",
    "        outputs = net(images)\r\n",
    "        loss = criterion(outputs, labels)  # calculate loss\r\n",
    "        optimizer.zero_grad()  # clear net state before backward\r\n",
    "        loss.backward()       \r\n",
    "        optimizer.step()   # update parameters\r\n",
    "\r\n",
    "        #if i%100 == 0:\r\n",
    "            #print(\"current loss = %.5f\" %loss.item())\r\n",
    "print(\"finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 96.14\n"
     ]
    }
   ],
   "source": [
    "# prediction\r\n",
    "total = 0\r\n",
    "correct = 0\r\n",
    "for images, labels in test_loader:\r\n",
    "    images = Variable(images.view(-1, 28*28))\r\n",
    "    labels = Variable(labels)\r\n",
    "    outputs = net(images)\r\n",
    "\r\n",
    "    _,predicts = torch.max(outputs.data, 1)\r\n",
    "    total += labels.size(0)\r\n",
    "    correct += (predicts == labels).sum()\r\n",
    "print(\"Accuracy = %.2f\" %(100*correct/total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit (conda)",
   "name": "python370jvsc74a57bd007efdcd4b820c98a756949507a4d29d7862823915ec7477944641bea022f4f62"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}